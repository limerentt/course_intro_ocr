{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from course_intro_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 packages.\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = Path().absolute().parent.parent / 'midv500' / 'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()\n",
    "\n",
    "data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "print(f\"Loaded {len(data_packs)} packages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cropper:\n",
    "    def __init__(self):\n",
    "        self.orb = cv2.ORB_create(nfeatures=2000)\n",
    "        \n",
    "    def preprocess_image(self, img):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return gray_img\n",
    "        \n",
    "    def detect_compute_keypoints_descriptors(self, img):\n",
    "        keypoints, descriptors = self.orb.detectAndCompute(img, None)\n",
    "        return keypoints, descriptors\n",
    "        \n",
    "    def match_keypoints(self, template_dscs, target_dscs):\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(template_dscs, target_dscs)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        return matches\n",
    "        \n",
    "    def find_homography(self, query_pts, train_pts):\n",
    "        homo, _ = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        return homo\n",
    "        \n",
    "    def transform_angles(self, homo, template_img):\n",
    "        template_angles = np.array([[0, 0], [len(template_img[0]), 0], [len(template_img[0]), len(template_img)], [0, len(template_img)]], dtype=np.float32)[:, None]\n",
    "        transformed_angles = cv2.perspectiveTransform(template_angles, homo)\n",
    "        return transformed_angles\n",
    "        \n",
    "    def normalize_coordinates(self, angles, target_img):\n",
    "        return angles / np.array([len(target_img[0]), len(target_img)])\n",
    "        \n",
    "    def angles(self, template_img, target_img):\n",
    "        template_gray = self.preprocess_image(template_img)\n",
    "        target_gray = self.preprocess_image(target_img)\n",
    "        template_kpts, template_dscs = self.detect_compute_keypoints_descriptors(template_gray)\n",
    "        target_kpts, target_dscs = self.detect_compute_keypoints_descriptors(target_gray)\n",
    "        matches = self.match_keypoints(template_dscs, target_dscs)\n",
    "        homo = self.find_homography(np.array([template_kpts[m.queryIdx].pt for m in matches], dtype=np.float32)[:, None],\n",
    "                                       np.array([target_kpts[m.trainIdx].pt for m in matches], dtype=np.float32)[:, None])\n",
    "        transformed_angles = self.transform_angles(homo, template_img)\n",
    "        normalized_angles = self.normalize_coordinates(transformed_angles, target_img)\n",
    "        return normalized_angles\n",
    "\n",
    "    def process_data_packs(self, data_packs):\n",
    "        results_dict = {}\n",
    "        for dp in tqdm(data_packs):\n",
    "            for i in range(len(dp)):\n",
    "                if dp[i].is_test_split():\n",
    "                    try:\n",
    "                        results_dict[dp[i].unique_key] = self.angles(np.array(dp.template_item.image), np.array(dp[i].image))\n",
    "                    except Exception as exc:\n",
    "                        pass\n",
    "        return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:32<03:02,  6.31s/it]"
     ]
    }
   ],
   "source": [
    "cropper = Cropper()\n",
    "results_dict = cropper.process_data_packs(data_packs)\n",
    "output_dict = {key: arr.squeeze() for key, arr in results_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Узнаем точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_intro_ocr_t1.metrics import dump_results_dict, measure_crop_accuracy\n",
    "\n",
    "dump_results_dict(results_dict, Path() / 'pred.json')\n",
    "acc = measure_crop_accuracy(\n",
    "    Path() / 'pred.json',\n",
    "    Path() / 'gt.json'\n",
    ")\n",
    "print(\"Точность кропа: {:1.4f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bae7ddeda0b50b85f5426381c5daf82e55ace4a8634779dfa04a3d620aaef92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
