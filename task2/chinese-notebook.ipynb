{"cells":[{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:08:24.668720Z","iopub.status.busy":"2024-05-24T14:08:24.667693Z","iopub.status.idle":"2024-05-24T14:08:24.673784Z","shell.execute_reply":"2024-05-24T14:08:24.672770Z","shell.execute_reply.started":"2024-05-24T14:08:24.668690Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","from pathlib import Path\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:08:24.675947Z","iopub.status.busy":"2024-05-24T14:08:24.675618Z","iopub.status.idle":"2024-05-24T14:08:24.705305Z","shell.execute_reply":"2024-05-24T14:08:24.704148Z","shell.execute_reply.started":"2024-05-24T14:08:24.675923Z"},"trusted":true},"outputs":[],"source":["from itertools import permutations\n","import zipfile\n","from typing import Optional, List\n","from pathlib import Path\n","import cv2\n","import numpy as np\n","from collections import defaultdict, Counter\n","import lmdb\n","\n","\n","class Vocabulary:\n","    def __init__(self, classes):\n","        self.classes = sorted(set(classes))\n","        self._class_to_index = dict((cls, idx) for idx, cls in enumerate(self.classes))\n","    \n","    def class_by_index(self, idx: int) -> str:\n","        return self.classes[idx]\n","\n","    def index_by_class(self, cls: str) -> int:\n","        return self._class_to_index[cls]\n","    \n","    def num_classes(self) -> int:\n","        return len(self.classes)\n","\n","\n","class ArchivedHWDBReader:\n","    def __init__(self, path: Path):\n","        self.path = path\n","        self.archive = None\n","    \n","    def open(self):\n","        self.archive = zipfile.ZipFile(self.path)\n","    \n","    def namelist(self):\n","        return self.archive.namelist()\n","    \n","    def decode_image(self, name):\n","        sample = self.archive.read(name)\n","        buf = np.asarray(bytearray(sample), dtype='uint8')\n","        return cv2.imdecode(buf, cv2.IMREAD_GRAYSCALE)\n","    \n","    def close(self):\n","        self.archive.close()\n","    \n","    def __enter__(self):\n","        self.open()\n","        return self\n","    \n","    def __exit__(self, exc_type, exc_value, traceback):\n","        self.close()\n","\n","\n","GB = 2**30\n","class LMDBReader:\n","    def __init__(self, path: Path):\n","        self.path = path\n","        self.env = None\n","        self.namelist_ = []\n","    \n","    def open(self):\n","        self.env = lmdb.open(self.path, \n","                             map_size=GB * 16,\n","                             lock=False, \n","                             subdir=False, \n","                             readonly=True)\n","        self.namelist_ = []\n","        with self.env.begin(buffers=True) as txn:\n","            cursor = txn.cursor()\n","            for key, _ in cursor:\n","                key = bytes(key).decode('utf-8')\n","                self.namelist_.append(key)\n","    \n","    def namelist(self):\n","        return self.namelist_\n","    \n","    def decode_image(self, name):\n","        key = name.encode('utf-8')\n","        with self.env.begin() as txn:\n","            sample = txn.get(key)\n","        buf = np.frombuffer(sample, dtype='uint8')\n","        return cv2.imdecode(buf, cv2.IMREAD_GRAYSCALE)\n","    \n","    def close(self):\n","        self.env.close()\n","    \n","    def __enter__(self):\n","        self.open()\n","        return self\n","    \n","    def __exit__(self, exc_type, exc_value, traceback):\n","        self.close()\n","\n","\n","class HWDBDatasetHelper:\n","    def __init__(self, reader, prefix='Train', vocabulary: Optional[Vocabulary]=None, namelist: Optional[List[str]]=None):\n","        self.reader = reader\n","        self.prefix = prefix\n","        self.index = defaultdict(list)\n","        self.counter = Counter()\n","        self.namelist = namelist\n","        if self.namelist is None:\n","            self.namelist = list(filter(lambda x: self.prefix in x, self.reader.namelist()))\n","        self.vocabulary = vocabulary\n","        self._build_index()\n","    \n","    def get_item(self, idx):\n","        name = self.namelist[idx]\n","        return self.reader.decode_image(name), \\\n","            self.vocabulary.index_by_class(HWDBDatasetHelper._get_class(name))\n","    \n","    def size(self):\n","        return len(self.namelist)\n","\n","    def get_all_class_items(self, idx):\n","        cls = self.vocabulary.class_by_index(idx)\n","        return self.index[cls]\n","    \n","    def most_common_classes(self, n=None):\n","        return self.counter.most_common(n)\n","    \n","    def train_val_split(self, train_part=0.8, seed=42):\n","        rnd = np.random.default_rng(seed)\n","        permutation = rnd.permutation(len(self.namelist))\n","        train_part = int(len(permutation) * train_part)\n","        train_names = [self.namelist[idx] for idx in permutation[:train_part]]\n","        val_names = [self.namelist[idx] for idx in permutation[train_part:]]\n","\n","        return HWDBDatasetHelper(self.reader, self.prefix, self.vocabulary, train_names),\\\n","            HWDBDatasetHelper(self.reader, self.prefix, self.vocabulary, val_names)\n","    \n","    @staticmethod\n","    def _get_class(name):\n","        return Path(name).parent.name\n","    \n","    def _build_index(self):\n","        classes = set()\n","        for idx, name in enumerate(self.namelist):\n","            cls = HWDBDatasetHelper._get_class(name)\n","            classes.add(cls)\n","            self.index[cls].append(idx)\n","            self.counter.update([cls])\n","        \n","        if self.vocabulary is None:\n","            self.vocabulary = Vocabulary(classes)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:08:24.706934Z","iopub.status.busy":"2024-05-24T14:08:24.706570Z","iopub.status.idle":"2024-05-24T14:08:24.720164Z","shell.execute_reply":"2024-05-24T14:08:24.719393Z","shell.execute_reply.started":"2024-05-24T14:08:24.706901Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","\n","def evaluate(gt_path, pred_path):\n","    gt = dict()\n","    with open(gt_path) as gt_f:\n","        for line in gt_f:\n","            name, cls = line.strip().split()\n","            gt[name] = cls\n","    \n","    n_good = 0\n","    n_all = len(gt)\n","    with open(pred_path) as pred_f:\n","        for line in pred_f:\n","            name, cls = line.strip().split()\n","            if cls == gt[name]:\n","                n_good += 1\n","    \n","    return n_good / n_all"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:08:24.722416Z","iopub.status.busy":"2024-05-24T14:08:24.722083Z","iopub.status.idle":"2024-05-24T14:08:24.731253Z","shell.execute_reply":"2024-05-24T14:08:24.730420Z","shell.execute_reply.started":"2024-05-24T14:08:24.722380Z"},"trusted":true},"outputs":[],"source":["root = Path().absolute().parent.parent / 'data'\n","train_path = os.path.join(root, 'train.lmdb')\n","test_path = os.path.join(root, 'test.lmdb')\n","gt_path = './gt.txt'\n","pred_path = './pred.txt'"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:08:24.732932Z","iopub.status.busy":"2024-05-24T14:08:24.732507Z","iopub.status.idle":"2024-05-24T14:09:44.275109Z","shell.execute_reply":"2024-05-24T14:09:44.274052Z","shell.execute_reply.started":"2024-05-24T14:08:24.732900Z"},"trusted":true},"outputs":[],"source":["train_reader = LMDBReader(train_path)\n","train_reader.open()\n","train_helper = HWDBDatasetHelper(train_reader)\n","train_helper, val_helper = train_helper.train_val_split()\n","train_dataset = HWDBDataset(train_helper)\n","val_dataset = HWDBDataset(val_helper)\n","train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True, num_workers=0)\n","val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=0)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:09:44.278416Z","iopub.status.busy":"2024-05-24T14:09:44.278110Z","iopub.status.idle":"2024-05-24T14:09:44.320429Z","shell.execute_reply":"2024-05-24T14:09:44.319459Z","shell.execute_reply.started":"2024-05-24T14:09:44.278391Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, helper: HWDBDatasetHelper):\n","        self.helper = helper\n","    \n","    def __len__(self):\n","        return len(self.helper)\n","    \n","    def __getitem__(self, idx):\n","        img, label = self.helper.get_item(idx)\n","        img = cv2.resize(img, (32, 104*32//79))\n","        img = (img - 127.5) / 255.\n","        img = torch.from_numpy(img).float()\n","        return img, label\n","\n","class CustomLoss(nn.Module):\n","    def __init__(self, in_features, out_features, s=30.0, m=0.50):\n","        super(CustomLoss, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.s = s\n","        self.m = m\n","        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n","        nn.init.xavier_uniform_(self.weight)\n","\n","    def forward(self, input, target):\n","        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n","        phi = cosine - self.m\n","        one_hot = F.one_hot(target, num_classes=self.out_features).float()\n","        output = one_hot * phi + (1.0 - one_hot) * cosine\n","        output *= self.s\n","        return F.cross_entropy(output, target)\n","\n","class CustomBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class CustomResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super().__init__()\n","        self.in_planes = 32\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(256*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        layers = []\n","        layers.append(block(self.in_planes, planes, stride))\n","        self.in_planes = planes * block.expansion\n","        for _ in range(1, num_blocks):\n","            layers.append(block(self.in_planes, planes, 1))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:09:44.322125Z","iopub.status.busy":"2024-05-24T14:09:44.321730Z","iopub.status.idle":"2024-05-24T14:09:44.388962Z","shell.execute_reply":"2024-05-24T14:09:44.388189Z","shell.execute_reply.started":"2024-05-24T14:09:44.322093Z"},"trusted":true},"outputs":[],"source":["model = ResNet(BasicBlock, [2,2,2,2], train_helper.vocabulary.num_classes())\n","model = model.to(device)\n","optim = torch.optim.AdamW(model.parameters(), lr=0.001)\n","loss_fn = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:09:44.390528Z","iopub.status.busy":"2024-05-24T14:09:44.390182Z","iopub.status.idle":"2024-05-24T14:09:44.400223Z","shell.execute_reply":"2024-05-24T14:09:44.399476Z","shell.execute_reply.started":"2024-05-24T14:09:44.390498Z"},"trusted":true},"outputs":[],"source":["def run_validation(val_loader: DataLoader, model: nn.Module, n_steps=None):\n","    model.eval()\n","    n_good = 0\n","    n_all = 0\n","    wrapper = lambda x: x\n","    if n_steps is None:\n","        n_steps = len(val_loader)\n","        wrapper = tqdm\n","    \n","    with torch.no_grad():\n","        for batch, (X, y) in enumerate(wrapper(val_loader)):\n","            if batch == n_steps:\n","                break\n","            logits = model(X.unsqueeze(1).to(torch.float32).to(device))\n","            classes = torch.argmax(logits, dim=1).cpu().numpy()\n","            n_good += sum(classes == y.cpu().numpy())\n","            n_all += len(classes)\n","    \n","    return n_good / n_all"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:09:44.403074Z","iopub.status.busy":"2024-05-24T14:09:44.402813Z","iopub.status.idle":"2024-05-24T16:25:22.988477Z","shell.execute_reply":"2024-05-24T16:25:22.987536Z","shell.execute_reply.started":"2024-05-24T14:09:44.403052Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:31<00:00,  7.28it/s]\n","100%|██████████| 1260/1260 [02:06<00:00,  9.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.896014483198342\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:01<00:00, 10.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9265647857848711\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:01<00:00, 10.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.938592231880101\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:02<00:00, 10.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9433036150596719\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:03<00:00, 10.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9461890851663567\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:01<00:00, 10.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9478970973101524\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 3141/5036 [07:10<04:19,  7.29it/s]IOPub message rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_msg_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n","100%|██████████| 1260/1260 [02:01<00:00, 10.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9511548861402804\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:01<00:00, 10.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9509501108423867\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5036/5036 [11:30<00:00,  7.29it/s]\n","100%|██████████| 1260/1260 [02:04<00:00, 10.14it/s]"]},{"name":"stdout","output_type":"stream","text":["accuracy: 0.9513394941739877\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for epoch in range(10):\n","    print(f'Epoch {epoch}:')\n","    for batch, (X, y) in enumerate(tqdm(train_loader)):\n","        model.train()\n","        logits = model(X.unsqueeze(1).to(torch.float32).to(device))\n","        loss = loss_fn(logits, y.to(torch.long).to(device))\n","        \n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","\n","    torch.save(model.state_dict(), f'my_epoch{epoch}.pth')\n","    \n","    accuracy = run_validation(val_loader, model)\n","    print(f'accuracy: {accuracy}')\n"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:25:22.992413Z","iopub.status.busy":"2024-05-24T16:25:22.991760Z","iopub.status.idle":"2024-05-24T16:25:32.331426Z","shell.execute_reply":"2024-05-24T16:25:32.330605Z","shell.execute_reply.started":"2024-05-24T16:25:22.992355Z"},"trusted":true},"outputs":[],"source":["test_reader = LMDBReader(test_path)\n","test_reader.open()\n","test_helper = HWDBDatasetHelper(test_reader, prefix='Test')\n","test_dataset = HWDBDataset(test_helper)\n","test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=0)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:25:32.332810Z","iopub.status.busy":"2024-05-24T16:25:32.332523Z","iopub.status.idle":"2024-05-24T16:28:02.862193Z","shell.execute_reply":"2024-05-24T16:28:02.861323Z","shell.execute_reply.started":"2024-05-24T16:25:32.332786Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1517/1517 [02:30<00:00, 10.08it/s]\n"]}],"source":["preds = []\n","model.eval()\n","with torch.no_grad():\n","    for X, _ in tqdm(test_loader):\n","        logits = model(X.unsqueeze(1).to(torch.float32).to(device))\n","        classes = torch.argmax(logits, dim=1).cpu().numpy()\n","        preds.extend(classes)"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:28:02.863747Z","iopub.status.busy":"2024-05-24T16:28:02.863460Z","iopub.status.idle":"2024-05-24T16:28:04.239086Z","shell.execute_reply":"2024-05-24T16:28:04.238190Z","shell.execute_reply.started":"2024-05-24T16:28:02.863723Z"},"trusted":true},"outputs":[],"source":["with open(pred_path, 'w', encoding=\"utf-8\") as f_pred:\n","    for idx, pred in enumerate(preds):\n","        name = test_helper.namelist[idx]\n","        cls = train_helper.vocabulary.class_by_index(pred)\n","        print(name, cls, file=f_pred)"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:28:04.240511Z","iopub.status.busy":"2024-05-24T16:28:04.240206Z","iopub.status.idle":"2024-05-24T16:28:05.927705Z","shell.execute_reply":"2024-05-24T16:28:05.926752Z","shell.execute_reply.started":"2024-05-24T16:28:04.240486Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.9310374580018879"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(gt_path, pred_path)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5076663,"sourceId":8505435,"sourceType":"datasetVersion"},{"datasetId":5076768,"sourceId":8505591,"sourceType":"datasetVersion"},{"datasetId":5076772,"sourceId":8505595,"sourceType":"datasetVersion"},{"datasetId":5077353,"sourceId":8506401,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
